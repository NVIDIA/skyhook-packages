[main]
include=nvidia-h100-performance
summary=Optimized for inference workloads

[bootloader]
# Isolate CPUs for inference processes (adjust based on your CPU count)
cmdline_isolcpus=isolcpus=8-63
# Allocate hugepages for better memory access
cmdline_hugepages=hugepagesz=2M hugepages=8192

[sysctl]
# Minimize latency
vm.swappiness=1
# Optimize for response time
kernel.sched_latency_ns=1000000
kernel.sched_min_granularity_ns=100000
