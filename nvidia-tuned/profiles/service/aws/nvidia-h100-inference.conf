[main]
include=nvidia-h100-performance
summary=Optimized for inference workloads (AWS-compatible)

[bootloader]
# Isolate CPUs for inference processes, 2 per socket
cmdline_isolcpus=isolcpus=${f:cpulist_invert:${f:calc_isolated_cores:2}}
# Allocate hugepages for better memory access
cmdline_hugepages=hugepagesz=2M hugepages=8192

[sysctl]
# Minimize latency
vm.swappiness=1
# Note: kernel.sched_latency_ns and kernel.sched_min_granularity_ns are not available on AWS kernels
